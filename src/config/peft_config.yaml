# src/config/peft_config.yaml

dataset:
  name: mnist  # Options: 'mnist', 'cifar10', 'custom'

model:
  name: resnet  # Using 'resnet' as the base model
  num_labels: 10

training:
  batch_size: 32
  epochs: 1
  learning_rate: 1e-4

federated_learning:
  num_clients: 5
  rounds: 5
  fraction_fit: 0.6
  num_shards: 50
  num_samples: 100
  partition_type: non_iid  # Options: 'iid', 'non_iid'

peft:
  lora_rank: 4             # Rank 'r' for LoRA matrices
  lora_alpha: 32           # Scaling factor for LoRA
  lora_dropout: 0.1        # Dropout rate for LoRA layers
  target_modules:
    - "fc"                 # Layers to apply LoRA to (e.g., 'fc' layer in ResNet)
  adaptive_rank: True      # Enable adaptive rank selection
  local_rank_budget: 2     # Budget for local rank selection in adaptive rank

fedbary:
  use_validation: true
